SECTION 0 - SCHEMA; HERE ARE THE ATTTRIBUTES AND SAMPLE DATA (ATTRIB >> SAMPLE DATA)
--SCHEMA - TRIPS 
medallion >> 89D227B655E5C82AECF13C3F540D4CF4
hack_license >> BA96DE419E711691B9445D6A6307C170
vendor_id >> CMT
rate_code >> 1
store_and_fwd_flag >> N
pickup_datetime >> 2013-01-01 15:11:48
dropoff_datetime >> 2013-01-01 15:18:10
passenger_count >> 4
trip_time_in_secs >> 382
trip_distance >> 1.00
pickup_longitude >>-73.978165
pickup_latitude >>40.757977
dropoff_longitude >> -73.989838 
dropoff_latitude >> 40.751171

-- SCHEMA - FARE :
medallion >> 89D227B655E5C82AECF13C3F540D4CF4
hack_license >> BA96DE419E711691B9445D6A6307C170
vendor_iD >> CMT
pickup_datetime >> 2013-01-01 15:11:48
payment_type >> CSH
fare_amount >> 6.5
surcharge >> 0
mta_tax >> 0.5
tip_amount >> 0 
tolls_amount >> 0
total_amount >> 7

SECTION I - SAMPLE DATA
----- 1.0 THROUGH 7.0
01.0
hbase(main):006:0> create_namespace 'trip'
0 row(s) in 0.0410 seconds

01.1 hbase(main):007:0> list

02.0 Create 'trip:trip', {NAME => 'data',VERSIONS=>1},{NAME => 'fare',VERSIONS=>1}
02.1 scan 'trip:trip'

03.0 sed -i~ 1d trip_data_1.csv # removes the first line which has the column information

Test Sample load of the trip_data
04.0  - cat trip_data_1.csv | sed -n '1,4p' > trip_data_1_sample.csv
05.0  - awk 'BEGIN {FS=OFS=","} {print $1":"$2":"$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14}' trip_data_1_sample.csv > trip_data_1_sample_key.csv
06.0    - hdfs dfs -copyFromLocal /mnt/hgfs/Documents/NYC_TaxiDemo/trip_data_1_sample_key.csv tripstaging/
07.0    - ./hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=, -Dimporttsv.columns=HBASE_ROW_KEY,data:rate_code,data:store_and_fwd_flag,data:pickup_datetime,data:dropoff_datetime,data:passenger_count,data:trip_time_in_secs,data:trip_distance,data:pickup_longitude,data:pickup_latitude,data:dropoff_longitude,data:dropoff_latitude trip:trip tripstaging/trip_data_1_sample_key.csv
    

SECTION 2 - ALL DATA    
    -------------------------------------------------------------------------------------
    ----- I HAVE NOT HAD MUCH TIME TO TEST THE BELOW SCRIPTS(4.0 THROUGH 6). 
    ----- I DID THE CHANGES BELOW, BUT HAVE NOT TRESTED IT. 
    ----- trip_data_1.csv.zip, and trIp_fare_1.csv.zip
    ----- PLEASE MODIFY BELOW SO YOU CAN INGEST INTO HBASE BOTH OF THESE FILES.
    ----- PLEASE MODIFY THE DATASET OR BETTER CREATE A SEPERATE SCRIPT ONCE THE TABLE IS   
          CREATED, TO INSERT THE TRACES (WORKINGTRACES.ZIP), INTO HBASE CELLS SO THAT WE 
          CAN QUERY A TRIP, THEN CLICK ON VIEW TRACE, AND LEAFLETTE WILL SHOW IT.
    
    ----- LOAD ALL TO HBASE
08.0  - awk 'BEGIN {FS=OFS=","} {print $1":"$2":"$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14}' trip_data_1.csv > trip_data_1_key.csv
09.0    - hdfs dfs -copyFromLocal /mnt/hgfs/Documents/NYC_TaxiDemo/trip_data_1_key.csv tripstaging/
10.0    - hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=, -Dimporttsv.columns=HBASE_ROW_KEY,data:rate_code,data:store_and_fwd_flag,data:pickup_datetime,data:dropoff_datetime,data:passenger_count,data:trip_time_in_secs,data:trip_distance,data:pickup_longitude,data:pickup_latitude,data:dropoff_longitude,data:dropoff_latitude trip:trip tripstaging/trip_data_1_key.csv
    
    
SECTION 3 - WORK IN PROGRESS WITH EXAMPLES OF HOW THINGS ARE CREATED IN PHOENIX    
 --- TO BE DOEN SEPERATRELY TO A DIFFERENT TABLE, BUT WITH SAME DATA. CREATE TABLE THROUGH PHOIENIX
 --- Through Phoenix
 11.0 /usr/hdp/current/phoenix-client/bin/psql.py sandbox.hortonworks.com:2181:/hbase-unsecure /root/phoenix/prices1.sql /root/phoenix/prices.csv
 
 
Create table phoenix_tripfare1 (
medallion  varchar(100),
hack_license varchar(100),
vendor_id varchar(100),
rate_code varchar(100),
store_and_fwd_flag varchar(100),
trip_distance varchar(100),
trip_time_in_secs varchar(100),
dropoff_datetime varchar(100),
dropoff_latitude varchar(100),
dropoff_longitude varchar(100),
passenger_count varchar(100),
pickup_datetime varchar(100),
pickup_latitude varchar(100),
pickup_longitude varchar(100),
rate_code varchar(100),
store_and_fwd_flag varchar(100),
trip_distance varchar(100),
trip_time_in_secs varchar(100),
CONSTRAINT pk PRIMARY KEY (VOLUME)

)
--Schema - DATA :  

medallion,
hack_license,
vendor_id,
rate_code,
store_and_fwd_flag,
pickup_datetime,
dropoff_datetime,
passenger_count,
trip_time_in_secs,
trip_distance,
pickup_longitude,
pickup_latitude,
dropoff_longitude,
dropoff_latitude

Example:
medallion                       ,hack_license                    ,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime    ,dropoff_datetime   ,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT      ,1        ,N                 ,2013-01-01 15:11:48,2013-01-01 15:18:10,4              ,382              ,1.00         ,-73.978165      ,40.757977      ,-73.989838        ,40.751171


-- Schema - FARE :
medallion,
hack_license,
vendor_id,
pickup_datetime,
payment_type,
fare_amount,
surcharge,
mta_tax,
tip_amount,
tolls_amount,
total_amount

Example:
medallion                       ,hack_license                    ,vendor_id,pickup_datetime    ,payment_type,fare_amount,surcharge,mta_tax,tip_amount,tolls_amount,total_amount
89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT      ,2013-01-01 15:11:48,CSH         ,6.5        ,0        ,0.5    ,0         ,0           ,7

PK ->> medallion+hack_license+vendor_id+pickup_datetime


-- Examples of creating Phoenix tables /* 

create table PRICES (
 SYMBOL varchar(10),
 DATE   varchar(10),
 TIME varchar(10),
 OPEN varchar(10),
 HIGH varchar(10),
 LOW    varchar(10),
 CLOSE     varchar(10),
 VOLUME varchar(30),
 CONSTRAINT pk PRIMARY KEY (VOLUME)
);

CREATE TABLE IF NOT EXISTS WEB_STAT (
     HOST CHAR(2) NOT NULL,
     DOMAIN VARCHAR NOT NULL,
     FEATURE VARCHAR NOT NULL,
     DATE DATE NOT NULL,
     USAGE.CORE BIGINT,
     USAGE.DB BIGINT,
     STATS.ACTIVE_VISITOR INTEGER
     CONSTRAINT PK PRIMARY KEY (HOST, DOMAIN, FEATURE, DATE)
);
*/ 
