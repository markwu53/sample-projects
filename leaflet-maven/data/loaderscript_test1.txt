SECTION I - SAMPLE DATA
----- 1.0 THROUGH 7.0
01.0
hbase(main):006:0> create_namespace 'trip_test1'
0 row(s) in 0.0410 seconds

01.1 hbase(main):007:0> list

02.0 create 'trip_test1:trip1', {NAME => 'trip',VERSIONS=>1},{NAME => 'fare',VERSIONS=>1}
02.1 scan 'trip_test1:trip1'
02.2 describe 'trip_test1:trip1'

03.0 sed -i~ 1d trip_data_1.csv # removes the first line which has the column information

Test Sample load of the trip_data
04.0  - cat trip_data_1.csv | sed -n '1,4p' > trip_data_1_sample.csv
05.0  - awk 'BEGIN {FS=OFS=","} {print $1":"$2":"$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14}' trip_data_1_sample.csv > trip_data_1_sample_key.csv
06.0    - hdfs dfs -copyFromLocal /mnt/hgfs/Documents/NYC_TaxiDemo/trip_data_1_sample_key.csv tripstaging/
07.0    - ./hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=, -Dimporttsv.columns=HBASE_ROW_KEY,data:rate_code,data:store_and_fwd_flag,data:pickup_datetime,data:dropoff_datetime,data:passenger_count,data:trip_time_in_secs,data:trip_distance,data:pickup_longitude,data:pickup_latitude,data:dropoff_longitude,data:dropoff_latitude trip:trip tripstaging/trip_data_1_sample_key.csv
    

SECTION 2 - ALL DATA    
SUGGESTED PK (medallion+hack_license+vendor_id+pickup_datetime)
Actual Implemented PK is medallion+hack_license >> $1:$2:$3
    -------------------------------------------------------------------------------------
    ----- I HAVE NOT HAD MUCH TIME TO TEST THE BELOW SCRIPTS(4.0 THROUGH 6). 
    ----- I DID THE CHANGES BELOW, BUT HAVE NOT TRESTED IT. 
    ----- trip_data_1.csv.zip, and trIp_fare_1.csv.zip
    ----- PLEASE MODIFY BELOW SO YOU CAN INGEST INTO HBASE BOTH OF THESE FILES.
    ----- PLEASE MODIFY THE DATASET OR BETTER CREATE A SEPERATE SCRIPT ONCE THE TABLE IS   
          CREATED, TO INSERT THE TRACES (WORKINGTRACES.ZIP), INTO HBASE CELLS SO THAT WE 
          CAN QUERY A TRIP, THEN CLICK ON VIEW TRACE, AND LEAFLETTE WILL SHOW IT.
    
    ----- LOAD ALL TO HBASE
Prep work >>>    (mkdir /opt/tripdata); (cd /opt/tripdata/) (cp  /mnt/hgfs/Documents/NYC_TaxiDemo/trip_data_1.csv /opt/tripdata
cp  /mnt/hgfs/Documents/NYC_TaxiDemo/trip_fare_1.csv /opt/tripdata);

08.0  - awk 'BEGIN {FS=OFS=","} {print $1":"$2":"$3,$4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14}' trip_data_1.csv > trip_data_1_key.csv
09.0  - hdfs dfs -mkdir /tripstaging
09.1  - hdfs dfs -copyFromLocal /opt/tripdata/trip_data_1_key.csv /tripstaging/

--->> trip_test1:trip1 == NAMESPACE:TABLE_NAME
10.0    - hbase org.apache.hadoop.hbase.mapreduce.ImportTsv -Dimporttsv.separator=, -Dimporttsv.columns=HBASE_ROW_KEY,trip:rate_code,trip:store_and_fwd_flag,trip:pickup_datetime,trip:dropoff_datetime,trip:passenger_count,trip:trip_time_in_secs,trip:trip_distance,trip:pickup_longitude,trip:pickup_latitude,trip:dropoff_longitude,trip:dropoff_latitude trip_test1:trip1 /tripstaging/trip_data_1_key.csv
    
---- VALIDATIONS 
-- scan 'trip_test1:trip1', {LIMIT => 10}
-- count 'trip_test1:trip1', INTERVAL => 100
-- get 'trip_test1:trip1', 'FEAF6C87C3422D111612942D665CA853:1C4724F3B307C59C161FDBCC948F7DCC:VTS'

--TEST ONLY (SCRAP): tripdetail trip_test1:trip1 /tripstaging/trip_data_1_key.csv
--put 'something', 'trip1','trip:tripdetail', 'image:header', 'image1.jpg'
---put 'something', 'trip1','trip:tripdetail', 'image:bodyimage', 	'image2.jpg'
	
-->>  ADD A COLUMN QUALIFIER NAMED 'TRIP_DETAIL' INTO THE TABLE WHICH CONTAINS THE TRIP XML (GPX OR KML);
 --- LEARNHBASE.WORDPRESS.COM FOR SYNTAX EXAMPLES;	

-- Setup the environment for leaflette and project:

	




    
SECTION 3 - WORK IN PROGRESS WITH EXAMPLES OF HOW THINGS ARE CREATED IN PHOENIX    
 --- TO BE DOEN SEPERATRELY TO A DIFFERENT TABLE, BUT WITH SAME DATA. CREATE TABLE THROUGH PHOIENIX
 --- Through Phoenix
 11.0 /usr/hdp/current/phoenix-client/bin/psql.py sandbox.hortonworks.com:2181:/hbase-unsecure /root/phoenix/prices1.sql /root/phoenix/prices.csv
 
 
Create table phoenix_tripfare1 (
medallion  varchar(100),
hack_license varchar(100),
vendor_id varchar(100),
rate_code varchar(100),
store_and_fwd_flag varchar(100),
trip_distance varchar(100),
trip_time_in_secs varchar(100),
dropoff_datetime varchar(100),
dropoff_latitude varchar(100),
dropoff_longitude varchar(100),
passenger_count varchar(100),
pickup_datetime varchar(100),
pickup_latitude varchar(100),
pickup_longitude varchar(100),
rate_code varchar(100),
store_and_fwd_flag varchar(100),
trip_distance varchar(100),
trip_time_in_secs varchar(100),
CONSTRAINT pk PRIMARY KEY (VOLUME)

)
--Schema - DATA :  

medallion,
hack_license,
vendor_id,
rate_code,
store_and_fwd_flag,
pickup_datetime,
dropoff_datetime,
passenger_count,
trip_time_in_secs,
trip_distance,
pickup_longitude,
pickup_latitude,
dropoff_longitude,
dropoff_latitude

Example:
medallion                       ,hack_license                    ,vendor_id,rate_code,store_and_fwd_flag,pickup_datetime    ,dropoff_datetime   ,passenger_count,trip_time_in_secs,trip_distance,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude
89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT      ,1        ,N                 ,2013-01-01 15:11:48,2013-01-01 15:18:10,4              ,382              ,1.00         ,-73.978165      ,40.757977      ,-73.989838        ,40.751171


-- Schema - FARE :
medallion,
hack_license,
vendor_id,
pickup_datetime,
payment_type,
fare_amount,
surcharge,
mta_tax,
tip_amount,
tolls_amount,
total_amount

Example:
medallion                       ,hack_license                    ,vendor_id,pickup_datetime    ,payment_type,fare_amount,surcharge,mta_tax,tip_amount,tolls_amount,total_amount
89D227B655E5C82AECF13C3F540D4CF4,BA96DE419E711691B9445D6A6307C170,CMT      ,2013-01-01 15:11:48,CSH         ,6.5        ,0        ,0.5    ,0         ,0           ,7

PK ->> medallion+hack_license+vendor_id+pickup_datetime


-- Examples of creating Phoenix tables /* 

create table PRICES (
 SYMBOL varchar(10),
 DATE   varchar(10),
 TIME varchar(10),
 OPEN varchar(10),
 HIGH varchar(10),
 LOW    varchar(10),
 CLOSE     varchar(10),
 VOLUME varchar(30),
 CONSTRAINT pk PRIMARY KEY (VOLUME)
);

CREATE TABLE IF NOT EXISTS WEB_STAT (
     HOST CHAR(2) NOT NULL,
     DOMAIN VARCHAR NOT NULL,
     FEATURE VARCHAR NOT NULL,
     DATE DATE NOT NULL,
     USAGE.CORE BIGINT,
     USAGE.DB BIGINT,
     STATS.ACTIVE_VISITOR INTEGER
     CONSTRAINT PK PRIMARY KEY (HOST, DOMAIN, FEATURE, DATE)
);
*/ 
